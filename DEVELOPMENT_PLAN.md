Development Plan: Local AI Agent Tool MVPThis document outlines the step-by-step plan to build the Minimum Viable Product (MVP) as defined in the PRD.md. We will tackle development in logical phases, ensuring a solid foundation before moving to more complex features.Phase 1: Project Setup & Foundation (The Groundwork)[ ] 1.1. Initialize Next.js Project:[ ] Create a new Next.js application using create-next-app.[ ] Configure with TypeScript and Tailwind CSS.[ ] Set up project structure as defined in README.md (/components, /lib, etc.).[ ] 1.2. Linter & Formatter Setup:[ ] Install and configure ESLint and Prettier.[ ] Add a lint script to package.json.[ ] Ensure it aligns with CODING_STYLE_GUIDE.md.[ ] 1.3. Version Control:[ ] Initialize a Git repository.[ ] Create an initial commit with the project boilerplate.[ ] Create a .gitignore file for Node.js.[ ] 1.4. Basic UI Layout:[ ] Implement the static three-panel layout from the mockup (Left, Center, Right).[ ] Use placeholder components for each panel's content for now.Phase 2: Ollama Integration (Connecting to the Brain)[ ] 2.1. Create Ollama API Client:[ ] Develop a TypeScript module (/lib/ollama-client.ts) to handle communication with the Ollama REST API.[ ] Implement a function to check the connection status (/api/tags).[ ] Implement a function to get the list of local models.[ ] Implement a function to send a prompt to the chat completion endpoint (/api/chat).[ ] 2.2. State Management for Connection:[ ] Create a React Context or a simple state management store (e.g., Zustand) to hold the application's global state.[ ] Manage Ollama connection status (connected, disconnected, loading).[ ] Store the list of available models.[ ] 2.3. Display Connection Status & Models:[ ] Implement FE-01: The UI in the header should reflect the connection status from the state manager.[ ] Implement FE-04: The "Model" dropdown in the right panel should be populated with the list of models fetched from the Ollama API.Phase 3: Core Chat Interface (The Conversation)[ ] 3.1. Build Chat Components:[ ] Create a ChatMessage component for displaying AI and user messages.[ ] Create a ChatHistory component to display an array of messages.[ ] Create a PromptInput component with a textarea and send button.[ ] 3.2. Implement State for Conversation:[ ] Manage the current conversation's message history in React state.[ ] Add a "loading" state to indicate when the AI is generating a response.[ ] 3.3. Wire Up Chat Functionality:[ ] On "Send", the PromptInput should:[ ] Add the user's message to the chat history.[ ] Set the "loading" state to true.[ ] Call the Ollama API client with the prompt and selected model.[ ] On response, add the AI's message to the history and set "loading" to false.[ ] 3.4. Implement Code Rendering:[ ] Implement FE-06: Use a library like react-syntax-highlighter to render code blocks within ChatMessage.[ ] Add a "Copy" button to the code block component.Phase 4: Agent Management (Creating Personas)[ ] 4.1. State Management for Agents:[ ] Define a data structure for an "Agent" (e.g., id, name, instructions).[ ] Use localStorage or a simple client-side store to persist the user's list of created agents.[ ] 4.2. Implement Agent List UI:[ ] The left panel should display the list of agents from the state manager.[ ] Implement functionality to highlight the currently "active" agent.[ ] Implement the ability to switch between agents.[ ] 4.3. Implement Agent Creation Workflow:[ ] Implement FE-03: The "Upload File" button should trigger a file input dialog.[ ] When a .txt file is selected, read its content.[ ] Implement the "+ New Agent" button flow: prompt the user for a name, use the uploaded text as instructions, and save the new agent to the state manager.[ ] 4.4. Integrate Instructions into Prompt:[ ] When sending a request to Ollama, ensure the content from the active agent's instruction file is correctly formatted and sent as the system prompt.[ ] The instructions viewer in the right panel should display the text of the active agent.